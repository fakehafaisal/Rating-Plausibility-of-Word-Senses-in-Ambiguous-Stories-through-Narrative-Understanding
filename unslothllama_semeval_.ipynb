{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 14304389,
          "sourceType": "datasetVersion",
          "datasetId": 9131261
        },
        {
          "sourceId": 14304518,
          "sourceType": "datasetVersion",
          "datasetId": 9131319
        }
      ],
      "dockerImageVersionId": 31236,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4f6df857bc6647cd83f86b88ec076560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cb9eb1180f34572bc2bbfaa160f71fa",
              "IPY_MODEL_c657d83f0453404db67cb2126c20e91d",
              "IPY_MODEL_77085b5b2cc84cbabffe5e566c8ad0bb"
            ],
            "layout": "IPY_MODEL_715b63de1699428ab3ee2713756777c5"
          }
        },
        "5cb9eb1180f34572bc2bbfaa160f71fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e60ae9051dbe4e17937eb0d7e0037e94",
            "placeholder": "​",
            "style": "IPY_MODEL_c5a97768448a47be84de98778218edca",
            "value": "Map: 100%"
          }
        },
        "c657d83f0453404db67cb2126c20e91d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4cc5246b6a74e9598703c6f8b69bf3b",
            "max": 7448,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_139dc8b7b9814a6ca47a0c81918f2720",
            "value": 7448
          }
        },
        "77085b5b2cc84cbabffe5e566c8ad0bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdf0ef1aeaaf44cea6a76d02e2400ab0",
            "placeholder": "​",
            "style": "IPY_MODEL_a90b77a8c59342a0b0b441d9f9cdb5a6",
            "value": " 7448/7448 [00:06&lt;00:00, 1133.29 examples/s]"
          }
        },
        "715b63de1699428ab3ee2713756777c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e60ae9051dbe4e17937eb0d7e0037e94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5a97768448a47be84de98778218edca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4cc5246b6a74e9598703c6f8b69bf3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "139dc8b7b9814a6ca47a0c81918f2720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdf0ef1aeaaf44cea6a76d02e2400ab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a90b77a8c59342a0b0b441d9f9cdb5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6076b75800ea48a3848b616b9a6b39e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50b76c15c787471aa4a714a601ea17bc",
              "IPY_MODEL_89544bf72a8f4512bdd24464a0fa15ef",
              "IPY_MODEL_5a8264132941484084e4fc53a2fc74d8"
            ],
            "layout": "IPY_MODEL_c67fe2e9a1ec4419959bab68145755cf"
          }
        },
        "50b76c15c787471aa4a714a601ea17bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fde109058bc4aee834cbc22ac13c134",
            "placeholder": "​",
            "style": "IPY_MODEL_bae1d888d6344b2d8d4b2764d98efafc",
            "value": "Map: 100%"
          }
        },
        "89544bf72a8f4512bdd24464a0fa15ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53ee26d9b80e4b0d80697b5b432ce82e",
            "max": 588,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d2c64833ed04586b68cffaa9895172d",
            "value": 588
          }
        },
        "5a8264132941484084e4fc53a2fc74d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e8128d739ee4acfb18f36273e342fd2",
            "placeholder": "​",
            "style": "IPY_MODEL_f3c831b936c14679ad16c9310b967e00",
            "value": " 588/588 [00:00&lt;00:00, 2099.02 examples/s]"
          }
        },
        "c67fe2e9a1ec4419959bab68145755cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fde109058bc4aee834cbc22ac13c134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bae1d888d6344b2d8d4b2764d98efafc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53ee26d9b80e4b0d80697b5b432ce82e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d2c64833ed04586b68cffaa9895172d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e8128d739ee4acfb18f36273e342fd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3c831b936c14679ad16c9310b967e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01398b884ace4be8b67017cbb3d152ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1341971bead143c69345641edae285a7",
              "IPY_MODEL_ca88c18212cf4edf90c5957eb49f486d",
              "IPY_MODEL_0b8fb46e0c274ef8960210a1b6dce13f"
            ],
            "layout": "IPY_MODEL_6f1e1cc4c44e4651a346b5ff76b91fc1"
          }
        },
        "1341971bead143c69345641edae285a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82248aed7833430f940540483bfd378b",
            "placeholder": "​",
            "style": "IPY_MODEL_580e9c498a5d4e33afd9d1b94a828aaa",
            "value": "Map: 100%"
          }
        },
        "ca88c18212cf4edf90c5957eb49f486d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3afd8cd963dd4f51a14c08dfec73dafc",
            "max": 7448,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a832275ba6d4a3393aaf9a2023a6667",
            "value": 7448
          }
        },
        "0b8fb46e0c274ef8960210a1b6dce13f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35a1527eaf2c462bb14b7afef08b1878",
            "placeholder": "​",
            "style": "IPY_MODEL_4fe165a03b2a475393aa4c303ca1255e",
            "value": " 7448/7448 [00:06&lt;00:00, 1147.91 examples/s]"
          }
        },
        "6f1e1cc4c44e4651a346b5ff76b91fc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82248aed7833430f940540483bfd378b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "580e9c498a5d4e33afd9d1b94a828aaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3afd8cd963dd4f51a14c08dfec73dafc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a832275ba6d4a3393aaf9a2023a6667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35a1527eaf2c462bb14b7afef08b1878": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fe165a03b2a475393aa4c303ca1255e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8892b0cbcae4924a27ff155ceda09be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60eb64326a4a42dfac87c22865c0d8be",
              "IPY_MODEL_aec93af47eb44c6692e09a04507d8cc7",
              "IPY_MODEL_998bb3c8315f4c78ade39337fe74cddb"
            ],
            "layout": "IPY_MODEL_c14a6f4c5d0a4bec88a7d0e798a47638"
          }
        },
        "60eb64326a4a42dfac87c22865c0d8be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f0a214138034584a9f38f183fea044d",
            "placeholder": "​",
            "style": "IPY_MODEL_4e7dfbe895324b06ba6caf353cdb1e00",
            "value": "Map: 100%"
          }
        },
        "aec93af47eb44c6692e09a04507d8cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d5385a7674e49388125ebb95421f1e5",
            "max": 588,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed22527afbec48149eb4d6220c590655",
            "value": 588
          }
        },
        "998bb3c8315f4c78ade39337fe74cddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bc368c285a3441cb8b0ee94f0d4e061",
            "placeholder": "​",
            "style": "IPY_MODEL_0209a24f0e8a42dfb84a0cdb5c9cc8e2",
            "value": " 588/588 [00:00&lt;00:00, 1231.79 examples/s]"
          }
        },
        "c14a6f4c5d0a4bec88a7d0e798a47638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f0a214138034584a9f38f183fea044d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e7dfbe895324b06ba6caf353cdb1e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d5385a7674e49388125ebb95421f1e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed22527afbec48149eb4d6220c590655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bc368c285a3441cb8b0ee94f0d4e061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0209a24f0e8a42dfb84a0cdb5c9cc8e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf58daa800b4404b83a67e902406683e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7090b0a59d0480089aaf0e4df4fb50d",
              "IPY_MODEL_3ee88d0ff07c498fa75f433eb636bd09",
              "IPY_MODEL_2d47d72d31104b06a7c668b6fc1bf632"
            ],
            "layout": "IPY_MODEL_eb83b5a04f7f41d6971c8db2ce37239e"
          }
        },
        "f7090b0a59d0480089aaf0e4df4fb50d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fd2d5c50c04432db506e086dba694b1",
            "placeholder": "​",
            "style": "IPY_MODEL_af96cc0dab72424caa92ec109afccad0",
            "value": "Map: 100%"
          }
        },
        "3ee88d0ff07c498fa75f433eb636bd09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d9abf0d4c2a439a9a06c12899f445d9",
            "max": 7448,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1225f7bc229421689f9883ab0d099ee",
            "value": 7448
          }
        },
        "2d47d72d31104b06a7c668b6fc1bf632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a69d72360de4a6aa3e326956dd3f693",
            "placeholder": "​",
            "style": "IPY_MODEL_81188c5cbe5c45ee8fd0cd19d7703a82",
            "value": " 7448/7448 [00:08&lt;00:00, 894.18 examples/s]"
          }
        },
        "eb83b5a04f7f41d6971c8db2ce37239e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fd2d5c50c04432db506e086dba694b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af96cc0dab72424caa92ec109afccad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d9abf0d4c2a439a9a06c12899f445d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1225f7bc229421689f9883ab0d099ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a69d72360de4a6aa3e326956dd3f693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81188c5cbe5c45ee8fd0cd19d7703a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c76f856c7f6246b2ba6b43e00a44a215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa6344fc907143f89ace452ce06fc9d9",
              "IPY_MODEL_9cb4f644f08f42869a6a09df6f614c81",
              "IPY_MODEL_98f83591ef7945e985b9875a952d9af8"
            ],
            "layout": "IPY_MODEL_6acbc3e085cc433787fc42b7e5c22c9a"
          }
        },
        "fa6344fc907143f89ace452ce06fc9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08d1f7d6249b468ead0f465f4b0524bf",
            "placeholder": "​",
            "style": "IPY_MODEL_cbc83b8fbd0f4abe9e3f104879d94cbe",
            "value": "Map: 100%"
          }
        },
        "9cb4f644f08f42869a6a09df6f614c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6655ebada14443c920a1b9f7ff5cafb",
            "max": 588,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51eae4f68f55430da9e8fbbf802b5052",
            "value": 588
          }
        },
        "98f83591ef7945e985b9875a952d9af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8bd838bc9c946b8ad1eef46e227bd31",
            "placeholder": "​",
            "style": "IPY_MODEL_32a095ce11264a509992d87ffc329a79",
            "value": " 588/588 [00:00&lt;00:00, 1082.63 examples/s]"
          }
        },
        "6acbc3e085cc433787fc42b7e5c22c9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08d1f7d6249b468ead0f465f4b0524bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbc83b8fbd0f4abe9e3f104879d94cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6655ebada14443c920a1b9f7ff5cafb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51eae4f68f55430da9e8fbbf802b5052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8bd838bc9c946b8ad1eef46e227bd31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32a095ce11264a509992d87ffc329a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U unsloth unsloth_zoo bitsandbytes accelerate transformers peft sentence-transformers scipy xformers\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-28T14:39:59.150873Z",
          "iopub.execute_input": "2025-12-28T14:39:59.151590Z",
          "iopub.status.idle": "2025-12-28T14:40:08.675759Z",
          "shell.execute_reply.started": "2025-12-28T14:39:59.151555Z",
          "shell.execute_reply": "2025-12-28T14:40:08.675017Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivgYnSnDavBU",
        "outputId": "1b823052-bed7-4e60-9219-038b80e51092"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth\n",
            "  Downloading unsloth-2025.12.9-py3-none-any.whl.metadata (65 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/65.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unsloth_zoo\n",
            "  Downloading unsloth_zoo-2025.12.7-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Collecting xformers\n",
            "  Downloading xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.45.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth) (25.0)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.24.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.9.5)\n",
            "Collecting tyro (from unsloth)\n",
            "  Downloading tyro-1.0.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.29.5)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.5.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.2.1)\n",
            "Collecting datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 (from unsloth)\n",
            "  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.36.0)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.36.0)\n",
            "Collecting trl!=0.19.0,<=0.24.0,>=0.18.2 (from unsloth)\n",
            "  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting torchao>=0.13.0 (from unsloth_zoo)\n",
            "  Downloading torchao-0.15.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo) (11.3.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo) (2025.11.3)\n",
            "Collecting msgspec (from unsloth_zoo)\n",
            "  Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo) (3.20.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Collecting torch>=2.4.0 (from unsloth)\n",
            "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (9.10.2.21)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.3.20)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton>=3.0.0 (from unsloth)\n",
            "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting pyarrow>=21.0.0 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.2.2)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.70.16)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth) (8.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from unsloth)\n",
            "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (0.17.0)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (4.4.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.17.0)\n",
            "Downloading unsloth-2025.12.9-py3-none-any.whl (376 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.1/376.1 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.12.7-py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.7/290.7 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl (122.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m146.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.3.0-py3-none-any.whl (506 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchao-0.15.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m136.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.24.0-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m132.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-1.0.3-py3-none-any.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchao, triton, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, tyro, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, torch, datasets, xformers, torchvision, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo, unsloth\n",
            "  Attempting uninstall: torchao\n",
            "    Found existing installation: torchao 0.10.0\n",
            "    Uninstalling torchao-0.10.0:\n",
            "      Successfully uninstalled torchao-0.10.0\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cu126\n",
            "    Uninstalling torch-2.9.0+cu126:\n",
            "      Successfully uninstalled torch-2.9.0+cu126\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.24.0+cu126\n",
            "    Uninstalling torchvision-0.24.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.24.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.49.0 cut_cross_entropy-25.1.1 datasets-4.3.0 msgspec-0.20.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 pyarrow-22.0.0 torch-2.9.1 torchao-0.15.0 torchvision-0.24.1 triton-3.5.1 trl-0.24.0 tyro-1.0.3 unsloth-2025.12.9 unsloth_zoo-2025.12.7 xformers-0.0.33.post2\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchaudio torchvision -y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqRlq-iqcw4z",
        "outputId": "14852b72-badd-4a77-b421-d20576454322"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.9.1\n",
            "Uninstalling torch-2.9.1:\n",
            "  Successfully uninstalled torch-2.9.1\n",
            "Found existing installation: torchaudio 2.9.0+cu126\n",
            "Uninstalling torchaudio-2.9.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "Found existing installation: torchvision 0.24.1\n",
            "Uninstalling torchvision-0.24.1:\n",
            "  Successfully uninstalled torchvision-0.24.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.9.1+cu128 torchvision==0.24.1+cu128 torchaudio==2.9.1+cu128 --index-url https://download.pytorch.org/whl/cu128\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O16RNuCGdGBo",
        "outputId": "b63c682a-b9de-48b9-8475-5cf74f301b6b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu128\n",
            "Collecting torch==2.9.1+cu128\n",
            "  Downloading https://download.pytorch.org/whl/cu128/torch-2.9.1%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting torchvision==0.24.1+cu128\n",
            "  Downloading https://download.pytorch.org/whl/cu128/torchvision-0.24.1%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Collecting torchaudio==2.9.1+cu128\n",
            "  Downloading https://download.pytorch.org/whl/cu128/torchaudio-2.9.1%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1+cu128) (3.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.24.1+cu128) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.24.1+cu128) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.1+cu128) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.1+cu128) (3.0.3)\n",
            "Downloading https://download.pytorch.org/whl/cu128/torch-2.9.1%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl (900.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m900.9/900.9 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu128/torchvision-0.24.1%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu128/torchaudio-2.9.1%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch, torchvision, torchaudio\n",
            "Successfully installed torch-2.9.1+cu128 torchaudio-2.9.1+cu128 torchvision-0.24.1+cu128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "print(torch.__version__, torchaudio.__version__)\n",
        "print(torch.__version__, torch.version.cuda, torch.cuda.is_available())\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "print(\"Unsloth import succeeded\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-28T14:40:23.015119Z",
          "iopub.execute_input": "2025-12-28T14:40:23.016036Z",
          "iopub.status.idle": "2025-12-28T14:40:23.050925Z",
          "shell.execute_reply.started": "2025-12-28T14:40:23.015992Z",
          "shell.execute_reply": "2025-12-28T14:40:23.050003Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF-3kTGEavBU",
        "outputId": "cd76e05a-a7a7-4d75-d20f-ef8acdde4be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.1+cu128 2.9.1+cu128\n",
            "2.9.1+cu128 12.8 True\n",
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "Unsloth import succeeded\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-28T14:35:36.128774Z",
          "iopub.execute_input": "2025-12-28T14:35:36.129515Z",
          "iopub.status.idle": "2025-12-28T14:35:36.168461Z",
          "shell.execute_reply.started": "2025-12-28T14:35:36.129481Z",
          "shell.execute_reply": "2025-12-28T14:35:36.167522Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY6VZIpLavBV",
        "outputId": "e7f58f10-abaa-4410-b84f-c808c451cf9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-27T00:01:15.855895Z",
          "iopub.execute_input": "2025-12-27T00:01:15.856471Z",
          "iopub.status.idle": "2025-12-27T00:01:16.092963Z",
          "shell.execute_reply.started": "2025-12-27T00:01:15.856431Z",
          "shell.execute_reply": "2025-12-27T00:01:16.092106Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWQQNw_gavBV",
        "outputId": "1e8bdb05-3ec8-4ef2-b227-e80934fa12df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec 29 09:43:43 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0             26W /   70W |     102MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "import gc, torch, os\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-27T00:01:25.526572Z",
          "iopub.execute_input": "2025-12-27T00:01:25.527217Z",
          "iopub.status.idle": "2025-12-27T00:01:27.582684Z",
          "shell.execute_reply.started": "2025-12-27T00:01:25.527187Z",
          "shell.execute_reply": "2025-12-27T00:01:27.581953Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-Q7RUSJavBV",
        "outputId": "a9b56489-702b-4c50-a1a5-c8b67dd9b702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import KLDivLoss\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig, PreTrainedModel\n",
        "from scipy.stats import spearmanr\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "print(\"✅ All imports successful!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-27T00:42:16.274326Z",
          "iopub.execute_input": "2025-12-27T00:42:16.274676Z",
          "iopub.status.idle": "2025-12-27T00:42:20.327949Z",
          "shell.execute_reply.started": "2025-12-27T00:42:16.274655Z",
          "shell.execute_reply": "2025-12-27T00:42:20.326825Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sMyZyclavBW",
        "outputId": "03e0f9ac-b2f9-4a37-9f15-7942fba374a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All imports successful!\n",
            "PyTorch version: 2.9.1+cu128\n",
            "CUDA available: True\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "def make_soft_labels_empirical(choices):\n",
        "    \"\"\"Use ACTUAL human rating distribution instead of Gaussian\"\"\"\n",
        "    counts = np.zeros(5, dtype=np.float32)\n",
        "    for rating in choices:\n",
        "        counts[rating - 1] += 1\n",
        "    probs = counts / counts.sum()\n",
        "    return probs\n",
        "\n",
        "def make_soft_labels_adaptive(avg, stdev, choices):\n",
        "    \"\"\"Adaptive smoothing based on agreement level\"\"\"\n",
        "    centers = np.arange(1, 6, dtype=np.float32)\n",
        "    num_ratings = len(choices)\n",
        "    unique_ratings = len(set(choices))\n",
        "    if unique_ratings == 1:\n",
        "        sigma = 0.3\n",
        "    elif unique_ratings == 2 and stdev < 1.0:\n",
        "        sigma = 0.5\n",
        "    else:\n",
        "        sigma = min(max(stdev, 0.4), 1.5)\n",
        "    dist = np.exp(-0.5 * ((centers - avg) / sigma)**2)\n",
        "    return dist / dist.sum()\n",
        "\n",
        "def mark_target_word(text, homonym):\n",
        "    \"\"\"Add [TGT] markers around the homonym\"\"\"\n",
        "    return text.replace(homonym, f\"[TGT] {homonym}\")\n",
        "\n",
        "print(\"✅ Helper functions defined!\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-27T00:43:15.760564Z",
          "iopub.execute_input": "2025-12-27T00:43:15.761226Z",
          "iopub.status.idle": "2025-12-27T00:43:15.768613Z",
          "shell.execute_reply.started": "2025-12-27T00:43:15.761199Z",
          "shell.execute_reply": "2025-12-27T00:43:15.767696Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsza5m04avBW",
        "outputId": "e2762ddb-3434-42e3-9290-137b1a47802b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Helper functions defined!\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "def load_json_file(file_path):\n",
        "    \"\"\"\n",
        "    Load either strict JSON or line-delimited JSON objects\n",
        "    \"\"\"\n",
        "    data_list = []\n",
        "    with open(file_path, \"r\") as f:\n",
        "        first_char = f.read(1)\n",
        "        f.seek(0)\n",
        "        if first_char in [\"{\", \"[\"]:\n",
        "            # normal JSON\n",
        "            data = json.load(f)\n",
        "            data_list = list(data.values()) if isinstance(data, dict) else data\n",
        "        else:\n",
        "            # line-delimited or Python-style\n",
        "            import ast\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    data_list.append(ast.literal_eval(line))\n",
        "    return data_list\n",
        "\n",
        "TRAIN_FILE = \"/content/combined_train.json\"\n",
        "DEV_FILE = \"/content/dev.json\"\n",
        "\n",
        "train_list = load_json_file(TRAIN_FILE)\n",
        "dev_list = load_json_file(DEV_FILE)\n",
        "\n",
        "print(f\"📊 Loaded {len(train_list)} training samples\")\n",
        "print(f\"📊 Loaded {len(dev_list)} dev samples\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-27T00:50:37.845973Z",
          "iopub.execute_input": "2025-12-27T00:50:37.846781Z",
          "iopub.status.idle": "2025-12-27T00:50:37.906746Z",
          "shell.execute_reply.started": "2025-12-27T00:50:37.846747Z",
          "shell.execute_reply": "2025-12-27T00:50:37.905942Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcotwIztavBW",
        "outputId": "2e5e404f-5ae4-4a4c-a4d0-e0c50a947b71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Loaded 7448 training samples\n",
            "📊 Loaded 588 dev samples\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "def check_types(data_list):\n",
        "    type_map = {}\n",
        "    for i, item in enumerate(data_list):\n",
        "        for key, value in item.items():\n",
        "            if key not in type_map:\n",
        "                type_map[key] = {}\n",
        "            val_type = type(value).__name__\n",
        "            if val_type not in type_map[key]:\n",
        "                type_map[key][val_type] = []\n",
        "            type_map[key][val_type].append(i)\n",
        "    print(\"\\n🔍 Checking for mixed types:\")\n",
        "    for key, types in type_map.items():\n",
        "        if len(types) > 1:\n",
        "            print(f\"\\n❌ Field '{key}' has mixed types:\")\n",
        "            for t, indices in types.items():\n",
        "                print(f\"   {t}: {len(indices)} occurrences (first at index {indices[0]})\")\n",
        "                if indices[0] < len(data_list):\n",
        "                    print(f\"      Example value: {data_list[indices[0]][key]}\")\n",
        "\n",
        "check_types(train_list)\n",
        "\n",
        "def clean_data(data_list):\n",
        "    \"\"\"Ensure all fields have consistent types for Arrow\"\"\"\n",
        "    cleaned = []\n",
        "    for item in data_list:\n",
        "        cleaned.append({\n",
        "            'id': int(item.get('id',0)) if item.get('id') is not None else 0,\n",
        "            'homonym': str(item.get('homonym','')),\n",
        "            'judged_meaning': str(item.get('judged_meaning','')),\n",
        "            'precontext': str(item.get('precontext') or ''),\n",
        "            'sentence': str(item.get('sentence','')),\n",
        "            'ending': str(item.get('ending') or ''),\n",
        "            'choices': list(item.get('choices', [])) if isinstance(item.get('choices'), list) else [],\n",
        "            'nonsensical': bool(item.get('nonsensical', False)),\n",
        "            'average': float(item.get('average',0)) if item.get('average') is not None else 0.0,\n",
        "            'stdev': float(item.get('stdev',0.0)) if item.get('stdev') is not None else 0.0,\n",
        "            'example_sentence': str(item.get('example_sentence') or '')\n",
        "        })\n",
        "    return cleaned\n",
        "\n",
        "train_list = clean_data(train_list)\n",
        "dev_list = clean_data(dev_list)\n",
        "print(\"✅ Data cleaned!\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-27T00:50:42.462342Z",
          "iopub.execute_input": "2025-12-27T00:50:42.462612Z",
          "iopub.status.idle": "2025-12-27T00:50:42.491388Z",
          "shell.execute_reply.started": "2025-12-27T00:50:42.462590Z",
          "shell.execute_reply": "2025-12-27T00:50:42.490644Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7knPZ1KavBW",
        "outputId": "e0260763-6f18-4564-8179-7a897363b661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Checking for mixed types:\n",
            "\n",
            "❌ Field 'average' has mixed types:\n",
            "   float: 5024 occurrences (first at index 0)\n",
            "      Example value: 3.0\n",
            "   int: 2424 occurrences (first at index 2281)\n",
            "      Example value: 5\n",
            "✅ Data cleaned!\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_ambistory(row):\n",
        "    story = (\n",
        "        row[\"precontext\"].strip() + \" \" +\n",
        "        row[\"sentence\"].strip() + \" \" +\n",
        "        row[\"ending\"].strip()\n",
        "    ).strip()\n",
        "    story = mark_target_word(story, row[\"homonym\"])\n",
        "\n",
        "    if row[\"example_sentence\"] and len(str(row[\"example_sentence\"]).strip()) > 0:\n",
        "        example = f\"Definition: {row['judged_meaning']}. Example: {row['example_sentence']}\"\n",
        "    else:\n",
        "        example = f\"Definition: {row['judged_meaning']}\"\n",
        "\n",
        "    labels = make_soft_labels_empirical(row[\"choices\"])\n",
        "    return {\n",
        "        \"story\": story,\n",
        "        \"example\": example,\n",
        "        \"labels\": labels,\n",
        "        \"stdev\": row[\"stdev\"]\n",
        "    }\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "train_ds = Dataset.from_list(train_list)\n",
        "dev_ds = Dataset.from_list(dev_list)\n",
        "\n",
        "train_ds = train_ds.map(preprocess_ambistory)\n",
        "dev_ds = dev_ds.map(preprocess_ambistory)\n",
        "\n",
        "print(\"✅ Preprocessing complete!\")\n",
        "print(f\"\\nExample preprocessed sample:\")\n",
        "print(f\"  Story (first 100 chars): {train_ds[0]['story'][:100]}...\")\n",
        "print(f\"  Example (first 100 chars): {train_ds[0]['example'][:100]}...\")\n",
        "print(f\"  Labels: {train_ds[0]['labels']}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-27T00:50:52.280626Z",
          "iopub.execute_input": "2025-12-27T00:50:52.281537Z",
          "iopub.status.idle": "2025-12-27T00:50:53.028131Z",
          "shell.execute_reply.started": "2025-12-27T00:50:52.281507Z",
          "shell.execute_reply": "2025-12-27T00:50:53.027086Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "4f6df857bc6647cd83f86b88ec076560",
            "5cb9eb1180f34572bc2bbfaa160f71fa",
            "c657d83f0453404db67cb2126c20e91d",
            "77085b5b2cc84cbabffe5e566c8ad0bb",
            "715b63de1699428ab3ee2713756777c5",
            "e60ae9051dbe4e17937eb0d7e0037e94",
            "c5a97768448a47be84de98778218edca",
            "a4cc5246b6a74e9598703c6f8b69bf3b",
            "139dc8b7b9814a6ca47a0c81918f2720",
            "fdf0ef1aeaaf44cea6a76d02e2400ab0",
            "a90b77a8c59342a0b0b441d9f9cdb5a6",
            "6076b75800ea48a3848b616b9a6b39e6",
            "50b76c15c787471aa4a714a601ea17bc",
            "89544bf72a8f4512bdd24464a0fa15ef",
            "5a8264132941484084e4fc53a2fc74d8",
            "c67fe2e9a1ec4419959bab68145755cf",
            "1fde109058bc4aee834cbc22ac13c134",
            "bae1d888d6344b2d8d4b2764d98efafc",
            "53ee26d9b80e4b0d80697b5b432ce82e",
            "8d2c64833ed04586b68cffaa9895172d",
            "4e8128d739ee4acfb18f36273e342fd2",
            "f3c831b936c14679ad16c9310b967e00"
          ]
        },
        "id": "4rPI6AlgavBX",
        "outputId": "003d5f14-7abe-40ce-f267-c66d3897e5e4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7448 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f6df857bc6647cd83f86b88ec076560"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/588 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6076b75800ea48a3848b616b9a6b39e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Preprocessing complete!\n",
            "\n",
            "Example preprocessed sample:\n",
            "  Story (first 100 chars): The old machine hummed in the corner of the workshop. Clara examined its dusty dials with a furrowed...\n",
            "  Example (first 100 chars): Definition: the difference in electrical charge between two points in a circuit expressed in volts. ...\n",
            "  Labels: [0.20000000298023224, 0.20000000298023224, 0.20000000298023224, 0.20000000298023224, 0.20000000298023224]\n"
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "\n",
        "# # model_name = \"unsloth/llama-3-8b-bnb-4bit\"\n",
        "# model_name = \"unsloth/mistral-7b-v0.3-bnb-4bit\"\n",
        "\n",
        "# base_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "#     model_name=model_name,\n",
        "#     max_seq_length=2048,\n",
        "#     load_in_4bit=True,\n",
        "#     device_map=\"auto\",\n",
        "#     offload_folder=\"offload\",\n",
        "#     output_hidden_states=True  # <-- important!,\n",
        "#     precision=\"fp16\"\n",
        "# )\n",
        "\n",
        "# # Attach LoRA adapters\n",
        "# base_model = FastLanguageModel.get_peft_model(\n",
        "#     base_model,\n",
        "#     r=16,\n",
        "#     lora_alpha=32,\n",
        "#     lora_dropout=0.0,\n",
        "#     bias=\"none\",\n",
        "#     target_modules=[\n",
        "#         \"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\n",
        "#         \"gate_proj\",\"up_proj\",\"down_proj\",\n",
        "#     ],\n",
        "# )\n",
        "model_name = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\"\n",
        "\n",
        "base_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=model_name,\n",
        "    max_seq_length=512,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        "    output_hidden_states=True,\n",
        "    torch_dtype=\"bfloat16\",\n",
        ")\n",
        "\n",
        "base_model = FastLanguageModel.get_peft_model(\n",
        "    base_model,\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.0,\n",
        "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\n",
        "                    \"gate_proj\",\"up_proj\",\"down_proj\"],\n",
        ")\n",
        "\n",
        "base_model.gradient_checkpointing_disable()\n",
        "print(\"✅ LLaMA + LoRA loaded.\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-27T01:10:45.848106Z",
          "iopub.execute_input": "2025-12-27T01:10:45.848424Z",
          "iopub.status.idle": "2025-12-27T01:11:00.237189Z",
          "shell.execute_reply.started": "2025-12-27T01:10:45.848401Z",
          "shell.execute_reply": "2025-12-27T01:11:00.235937Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0H2mW6KavBX",
        "outputId": "976a3c97-d11c-4284-c72b-3fcebbb6e836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.12.9: Fast Llama patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "✅ LLaMA + LoRA loaded.\n"
          ]
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import KLDivLoss\n",
        "from transformers import PreTrainedModel\n",
        "\n",
        "class SoftLLaMAModel(PreTrainedModel):\n",
        "    config_class = base_model.config_class\n",
        "\n",
        "    def __init__(self, config, base_model):\n",
        "        super().__init__(config)\n",
        "        self.backbone = base_model\n",
        "        hidden = config.hidden_size\n",
        "        self.classifier = nn.Linear(hidden, 5)\n",
        "        self.kl_loss = KLDivLoss(reduction=\"batchmean\")\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
        "        outputs = self.backbone(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        # Use hidden_states instead of last_hidden_state\n",
        "        hidden_states = outputs.hidden_states[-1]  # last layer\n",
        "        pooled = hidden_states.mean(dim=1)        # mean pooling over sequence\n",
        "        logits = self.classifier(pooled)\n",
        "        # hidden = outputs.hidden_states.mean(dim=1)\n",
        "        # logits = self.classifier(hidden)\n",
        "\n",
        "        if labels is None:\n",
        "            return {\"logits\": logits}\n",
        "\n",
        "        log_probs = torch.log_softmax(logits, dim=-1)\n",
        "        kl_loss = self.kl_loss(log_probs, labels)\n",
        "\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        centers = torch.tensor([1,2,3,4,5], dtype=torch.float32, device=logits.device)\n",
        "        pred_score = (probs * centers).sum(dim=-1)\n",
        "        true_score = (labels * centers).sum(dim=-1)\n",
        "        mse_loss = F.mse_loss(pred_score, true_score)\n",
        "\n",
        "        loss = 0.7 * kl_loss + 0.3 * mse_loss\n",
        "        return {\"loss\": loss, \"logits\": logits, \"kl_loss\": kl_loss, \"mse_loss\": mse_loss}\n",
        "\n",
        "\n",
        "model = SoftLLaMAModel(base_model.config, base_model)\n",
        "model.to(device)\n",
        "print(\"✅ Soft-label LLaMA model initialized\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-27T00:51:24.224675Z",
          "iopub.execute_input": "2025-12-27T00:51:24.225084Z",
          "iopub.status.idle": "2025-12-27T00:51:24.651417Z",
          "shell.execute_reply.started": "2025-12-27T00:51:24.225054Z",
          "shell.execute_reply": "2025-12-27T00:51:24.650404Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ieIdBGTavBX",
        "outputId": "4a601047-ed00-4f8d-91f2-a25c4623a63e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Soft-label LLaMA model initialized\n"
          ]
        }
      ],
      "execution_count": 29
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_fn(row):\n",
        "    enc = tokenizer(\n",
        "        row[\"story\"],\n",
        "        row[\"example\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128,  # smaller seq length saves memory\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    enc[\"labels\"] = torch.tensor(row[\"labels\"], dtype=torch.float32)\n",
        "    return enc\n",
        "\n",
        "train_tok = train_ds.map(tokenize_fn)\n",
        "dev_tok = dev_ds.map(tokenize_fn)\n",
        "\n",
        "train_tok.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "dev_tok.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "print(\"✅ Tokenization complete!\")\n",
        "print(f\"Train samples: {len(train_tok)}, Dev samples: {len(dev_tok)}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-27T00:53:19.075025Z",
          "iopub.execute_input": "2025-12-27T00:53:19.075333Z",
          "iopub.status.idle": "2025-12-27T00:53:22.174155Z",
          "shell.execute_reply.started": "2025-12-27T00:53:19.075310Z",
          "shell.execute_reply": "2025-12-27T00:53:22.173158Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "01398b884ace4be8b67017cbb3d152ce",
            "1341971bead143c69345641edae285a7",
            "ca88c18212cf4edf90c5957eb49f486d",
            "0b8fb46e0c274ef8960210a1b6dce13f",
            "6f1e1cc4c44e4651a346b5ff76b91fc1",
            "82248aed7833430f940540483bfd378b",
            "580e9c498a5d4e33afd9d1b94a828aaa",
            "3afd8cd963dd4f51a14c08dfec73dafc",
            "4a832275ba6d4a3393aaf9a2023a6667",
            "35a1527eaf2c462bb14b7afef08b1878",
            "4fe165a03b2a475393aa4c303ca1255e",
            "e8892b0cbcae4924a27ff155ceda09be",
            "60eb64326a4a42dfac87c22865c0d8be",
            "aec93af47eb44c6692e09a04507d8cc7",
            "998bb3c8315f4c78ade39337fe74cddb",
            "c14a6f4c5d0a4bec88a7d0e798a47638",
            "0f0a214138034584a9f38f183fea044d",
            "4e7dfbe895324b06ba6caf353cdb1e00",
            "8d5385a7674e49388125ebb95421f1e5",
            "ed22527afbec48149eb4d6220c590655",
            "0bc368c285a3441cb8b0ee94f0d4e061",
            "0209a24f0e8a42dfb84a0cdb5c9cc8e2"
          ]
        },
        "id": "G6wiiyMJavBX",
        "outputId": "5d54bb0c-aa74-4e77-c6e0-5f205948382c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7448 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01398b884ace4be8b67017cbb3d152ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/588 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8892b0cbcae4924a27ff155ceda09be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tokenization complete!\n",
            "Train samples: 7448, Dev samples: 588\n"
          ]
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import spearmanr\n",
        "import numpy as np\n",
        "\n",
        "# def compute_metrics(eval_pred):\n",
        "#     # Unpack values safely (Unsloth may wrap logits)\n",
        "#     logits, labels = eval_pred\n",
        "\n",
        "#     # Convert logits to a single 2-D array\n",
        "#     if isinstance(logits, tuple):\n",
        "#         logits = logits[0]\n",
        "\n",
        "#     # If logits are a list of tensors → stack\n",
        "#     if isinstance(logits, list):\n",
        "#         logits = np.vstack([np.array(x) for x in logits])\n",
        "#     else:\n",
        "#         logits = np.array(logits)\n",
        "\n",
        "#     # Same for labels\n",
        "#     if isinstance(labels, list):\n",
        "#         labels = np.vstack([np.array(x) for x in labels])\n",
        "#     else:\n",
        "#         labels = np.array(labels)\n",
        "\n",
        "#     # Convert logits → probabilities\n",
        "#     logits_exp = np.exp(logits - np.max(logits, axis=-1, keepdims=True))\n",
        "#     probs = logits_exp / np.sum(logits_exp, axis=-1, keepdims=True)\n",
        "\n",
        "#     centers = np.array([1, 2, 3, 4, 5])\n",
        "#     pred_scores = np.sum(probs * centers, axis=1)\n",
        "#     true_scores = np.sum(labels * centers, axis=1)\n",
        "\n",
        "#     spear = spearmanr(pred_scores, true_scores).correlation\n",
        "#     acc_1 = np.mean(np.abs(pred_scores - true_scores) <= 1.0)\n",
        "\n",
        "#     return {\n",
        "#         \"spearman\": float(spear),\n",
        "#         \"accuracy_within_sd\": float(acc_1),\n",
        "#     }\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "\n",
        "    # Convert to numpy first (they're already numpy arrays from Trainer)\n",
        "    if isinstance(logits, tuple):\n",
        "        logits = logits[0]\n",
        "\n",
        "    logits = np.array(logits)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Compute probabilities\n",
        "    # Apply softmax manually\n",
        "    logits_exp = np.exp(logits - np.max(logits, axis=-1, keepdims=True))\n",
        "    probs = logits_exp / np.sum(logits_exp, axis=-1, keepdims=True)\n",
        "\n",
        "    centers = np.array([1, 2, 3, 4, 5])\n",
        "\n",
        "    # Compute predicted scores (expected value)\n",
        "    pred_scores = np.sum(probs * centers, axis=1)\n",
        "\n",
        "    # Compute true scores (expected value from soft labels)\n",
        "    true_scores = np.sum(labels * centers, axis=1)\n",
        "\n",
        "    # Spearman correlation\n",
        "    spear = spearmanr(pred_scores, true_scores).correlation\n",
        "\n",
        "    # Accuracy within stdev\n",
        "    # Get stdevs from original dataset\n",
        "    try:\n",
        "        stdevs = np.array([dev_ds[i][\"stdev\"] for i in range(len(pred_scores))])\n",
        "        stdevs = np.maximum(stdevs, 1.0)  # Minimum threshold of 1.0\n",
        "        sd_acc = np.mean(np.abs(pred_scores - true_scores) <= stdevs)\n",
        "    except:\n",
        "        # Fallback if stdev not available\n",
        "        sd_acc = np.mean(np.abs(pred_scores - true_scores) <= 1.0)\n",
        "\n",
        "    # Also compute fixed ±1.0 accuracy\n",
        "    acc_1 = np.mean(np.abs(pred_scores - true_scores) <= 1.0)\n",
        "\n",
        "    return {\n",
        "        \"spearman\": float(spear),\n",
        "        \"sd_accuracy\": float(sd_acc),\n",
        "        \"accuracy_1\": float(acc_1)\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"✅ Metrics function ready\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-27T00:52:10.591215Z",
          "iopub.execute_input": "2025-12-27T00:52:10.592055Z",
          "iopub.status.idle": "2025-12-27T00:52:10.599305Z",
          "shell.execute_reply.started": "2025-12-27T00:52:10.592027Z",
          "shell.execute_reply": "2025-12-27T00:52:10.598380Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOJ0b170avBX",
        "outputId": "66797538-5222-404d-d23a-8d81b2bf1233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Metrics defined (FIXED)!\n",
            "✅ Metrics function ready\n"
          ]
        }
      ],
      "execution_count": 31
    },
    {
      "cell_type": "code",
      "source": [
        "train_tok.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "dev_tok.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n"
      ],
      "metadata": {
        "id": "Jft6Ra6BfPL3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example for a single batch\n",
        "batch = train_tok[0]\n",
        "print(type(batch))\n",
        "print(batch.keys() if isinstance(batch, dict) else batch)\n",
        "print(batch['input_ids'].shape if 'input_ids' in batch else batch.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmwOQ7mZfKlq",
        "outputId": "2d099284-3eea-4ab1-a1ad-7c76aed906f6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
            "torch.Size([1, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_tok:\n",
        "    print(batch['input_ids'].shape)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1OCPHyCfSir",
        "outputId": "aa037e86-e63c-4a76-a90d-944ec2ea943e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_batch(batch):\n",
        "    batch['input_ids'] = batch['input_ids'].squeeze(0)\n",
        "    batch['attention_mask'] = batch['attention_mask'].squeeze(0)\n",
        "    batch['labels'] = batch['labels'].squeeze(0)\n",
        "    return batch\n",
        "\n",
        "train_tok = train_tok.map(flatten_batch)\n",
        "dev_tok = dev_tok.map(flatten_batch)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "bf58daa800b4404b83a67e902406683e",
            "f7090b0a59d0480089aaf0e4df4fb50d",
            "3ee88d0ff07c498fa75f433eb636bd09",
            "2d47d72d31104b06a7c668b6fc1bf632",
            "eb83b5a04f7f41d6971c8db2ce37239e",
            "6fd2d5c50c04432db506e086dba694b1",
            "af96cc0dab72424caa92ec109afccad0",
            "4d9abf0d4c2a439a9a06c12899f445d9",
            "d1225f7bc229421689f9883ab0d099ee",
            "3a69d72360de4a6aa3e326956dd3f693",
            "81188c5cbe5c45ee8fd0cd19d7703a82",
            "c76f856c7f6246b2ba6b43e00a44a215",
            "fa6344fc907143f89ace452ce06fc9d9",
            "9cb4f644f08f42869a6a09df6f614c81",
            "98f83591ef7945e985b9875a952d9af8",
            "6acbc3e085cc433787fc42b7e5c22c9a",
            "08d1f7d6249b468ead0f465f4b0524bf",
            "cbc83b8fbd0f4abe9e3f104879d94cbe",
            "f6655ebada14443c920a1b9f7ff5cafb",
            "51eae4f68f55430da9e8fbbf802b5052",
            "f8bd838bc9c946b8ad1eef46e227bd31",
            "32a095ce11264a509992d87ffc329a79"
          ]
        },
        "id": "QxzRjrtWfb0-",
        "outputId": "0c636f09-ccca-4458-a998-916feb478311"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7448 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf58daa800b4404b83a67e902406683e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/588 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c76f856c7f6246b2ba6b43e00a44a215"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./llama_output\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=1,  # keep 1 to fit in memory\n",
        "    gradient_accumulation_steps=4,  # emulate batch size 4\n",
        "    per_device_eval_batch_size=1,\n",
        "    learning_rate=1e-5,\n",
        "    fp16=True,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy_1\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tok,\n",
        "    eval_dataset=dev_tok,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(\"🚀 Starting training...\")\n",
        "trainer.train()\n",
        "print(\"✅ Training complete!\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-27T00:53:25.289134Z",
          "iopub.execute_input": "2025-12-27T00:53:25.289412Z",
          "iopub.status.idle": "2025-12-27T00:53:28.608724Z",
          "shell.execute_reply.started": "2025-12-27T00:53:25.289392Z",
          "shell.execute_reply": "2025-12-27T00:53:28.607183Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "XGDU_dF8avBX",
        "outputId": "72e4b10f-2fb0-44f2-8ef6-eee0b0f0a380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2925598465.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer._unsloth___init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 7,448 | Num Epochs = 3 | Total steps = 5,586\n",
            "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4\n",
            " \"-____-\"     Trainable parameters = 11,282,437 of 1,247,096,837 (0.90% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5586' max='5586' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5586/5586 1:02:38, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Spearman</th>\n",
              "      <th>Sd Accuracy</th>\n",
              "      <th>Accuracy 1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.698800</td>\n",
              "      <td>0.808441</td>\n",
              "      <td>0.495284</td>\n",
              "      <td>0.726190</td>\n",
              "      <td>0.675170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.609300</td>\n",
              "      <td>0.796722</td>\n",
              "      <td>0.515195</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.687075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.533600</td>\n",
              "      <td>0.811679</td>\n",
              "      <td>0.514463</td>\n",
              "      <td>0.755102</td>\n",
              "      <td>0.687075</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['backbone.base_model.model.lm_head.weight'].\n",
            "There were unexpected keys in the checkpoint model loaded: ['backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.0.mlp.up_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.0.mlp.up_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.0.mlp.up_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.0.mlp.up_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.0.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.1.mlp.up_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.1.mlp.up_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.1.mlp.up_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.1.mlp.up_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.1.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.2.mlp.up_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.2.mlp.up_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.2.mlp.up_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.2.mlp.up_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.2.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.3.mlp.up_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.3.mlp.up_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.3.mlp.up_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.3.mlp.up_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.3.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.4.mlp.up_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.4.mlp.up_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.4.mlp.up_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.4.mlp.up_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.4.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.5.mlp.up_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.5.mlp.up_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.5.mlp.up_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.5.mlp.up_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.5.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.6.mlp.up_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.6.mlp.up_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.6.mlp.up_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.6.mlp.up_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.6.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.7.mlp.up_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.7.mlp.up_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.7.mlp.up_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.7.mlp.up_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.7.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.8.mlp.up_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.8.mlp.up_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.8.mlp.up_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.8.mlp.up_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.8.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.9.mlp.up_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.9.mlp.up_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.9.mlp.up_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.9.mlp.up_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.9.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.10.mlp.up_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.10.mlp.up_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.10.mlp.up_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.10.mlp.up_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.10.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.11.mlp.up_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.11.mlp.up_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.11.mlp.up_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.11.mlp.up_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.11.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.12.mlp.up_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.12.mlp.up_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.12.mlp.up_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.12.mlp.up_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.12.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.13.mlp.up_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.13.mlp.up_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.13.mlp.up_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.13.mlp.up_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.13.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.14.mlp.up_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.14.mlp.up_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.14.mlp.up_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.14.mlp.up_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.14.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.15.mlp.up_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.15.mlp.up_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.15.mlp.up_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.15.mlp.up_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.15.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'backbone.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.nested_absmax', 'backbone.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.nested_quant_map', 'backbone.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.quant_map', 'backbone.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.absmax', 'backbone.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training complete!\n"
          ]
        }
      ],
      "execution_count": 33
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Save the best model\n",
        "# ============================================================\n",
        "MODEL_SAVE_DIR = \"./best_llama_model\"\n",
        "\n",
        "print(\"💾 Saving best model...\")\n",
        "trainer.save_model(MODEL_SAVE_DIR)\n",
        "tokenizer.save_pretrained(MODEL_SAVE_DIR)\n",
        "\n",
        "# Save training info\n",
        "training_info = {\n",
        "    \"model_name\": model_name,\n",
        "    \"num_epochs\": training_args.num_train_epochs,\n",
        "    \"learning_rate\": training_args.learning_rate,\n",
        "    \"batch_size\": training_args.per_device_train_batch_size,\n",
        "    \"modifications\": [\n",
        "        \"Empirical soft labels from actual ratings\",\n",
        "        \"Rich meaning representation (definition + example)\",\n",
        "        \"Hybrid loss (KL + MSE)\",\n",
        "        \"Adaptive smoothing based on agreement\",\n",
        "        \"Optimized for accuracy metric\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open(f\"{MODEL_SAVE_DIR}/training_info.json\", \"w\") as f:\n",
        "    json.dump(training_info, f, indent=2)\n",
        "\n",
        "print(f\"✅ Model saved to: {MODEL_SAVE_DIR}\")\n",
        "print(\"\\n📊 Final metrics on validation set:\")\n",
        "\n",
        "# Get final evaluation\n",
        "final_metrics = trainer.evaluate()\n",
        "for key, value in final_metrics.items():\n",
        "    if key.startswith(\"eval_\"):\n",
        "        print(f\"   {key}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "xvBX9-Ubu9LD",
        "outputId": "3a836626-3065-455a-8242-18c830470110"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Saving best model...\n",
            "✅ Model saved to: ./best_llama_model\n",
            "\n",
            "📊 Final metrics on validation set:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='588' max='588' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [588/588 00:46]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   eval_loss: 0.7967\n",
            "   eval_spearman: 0.5152\n",
            "   eval_sd_accuracy: 0.7381\n",
            "   eval_accuracy_1: 0.6871\n",
            "   eval_runtime: 46.5026\n",
            "   eval_samples_per_second: 12.6440\n",
            "   eval_steps_per_second: 12.6440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from safetensors.torch import load_file\n",
        "print(\"🔮 Generating predictions...\")\n",
        "\n",
        "# Reload best model\n",
        "model = SoftLLaMAModel(base_model.config, base_model)\n",
        "state_dict = load_file(f\"{MODEL_SAVE_DIR}/model.safetensors\")\n",
        "model.load_state_dict(state_dict)\n",
        "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.eval()\n",
        "\n",
        "all_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(len(dev_tok)), desc=\"Predicting\"):\n",
        "        sample = {\n",
        "            \"input_ids\": dev_tok[i][\"input_ids\"].unsqueeze(0).to(model.device),\n",
        "            \"attention_mask\": dev_tok[i][\"attention_mask\"].unsqueeze(0).to(model.device)\n",
        "        }\n",
        "\n",
        "        outputs = model(**sample)\n",
        "        logits = outputs[\"logits\"]\n",
        "        probs = torch.softmax(logits, dim=-1).cpu().numpy()[0]\n",
        "\n",
        "        # Compute expected value\n",
        "        centers = np.array([1, 2, 3, 4, 5])\n",
        "        pred_score = (probs * centers).sum()\n",
        "        pred_class = int(np.clip(np.round(pred_score), 1, 5))\n",
        "\n",
        "        all_predictions.append(pred_class)\n",
        "\n",
        "print(f\"✅ Generated {len(all_predictions)} predictions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "8vcmY_-5vN_W",
        "outputId": "32bef1f9-e0df-4e19-d8e2-4d4ae9c3addb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔮 Generating predictions...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for SoftLLaMAModel:\n\tMissing key(s) in state_dict: \"backbone.base_model.model.lm_head.weight\". \n\tUnexpected key(s) in state_dict: \"backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.0.mlp.up_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.0.mlp.up_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.0.mlp.up_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.0.mlp.up_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.0.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.1.mlp.up_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.1.mlp.up_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.1.mlp.up_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.1.mlp.up_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.1.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.2.mlp.up_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.2.mlp.up_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.2.mlp.up_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.2.mlp.up_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.2.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.3.mlp.up_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.3.mlp.up_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.3.mlp.up_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.3.mlp.up_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.3.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.4.mlp.up_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.4.mlp.up_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.4.mlp.up_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.4.mlp.up_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.4.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.5.mlp.up_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.5.mlp.up_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.5.mlp.up_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.5.mlp.up_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.5.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.6.mlp.up_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.6.mlp.up_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.6.mlp.up_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.6.mlp.up_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.6.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.7.mlp.up_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.7.mlp.up_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.7.mlp.up_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.7.mlp.up_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.7.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.8.mlp.up_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.8.mlp.up_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.8.mlp.up_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.8.mlp.up_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.8.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.9.mlp.up_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.9.mlp.up_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.9.mlp.up_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.9.mlp.up_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.9.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.10.mlp.up_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.10.mlp.up_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.10.mlp.up_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.10.mlp.up_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.10.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.11.mlp.up_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.11.mlp.up_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.11.mlp.up_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.11.mlp.up_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.11.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.12.mlp.up_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.12.mlp.up_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.12.mlp.up_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.12.mlp.up_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.12.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.13.mlp.up_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.13.mlp.up_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.13.mlp.up_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.13.mlp.up_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.13.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.14.mlp.up_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.14.mlp.up_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.14.mlp.up_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.14.mlp.up_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.14.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.15.mlp.up_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.15.mlp.up_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.15.mlp.up_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.15.mlp.up_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.15.mlp.up_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-316403222.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSoftLLaMAModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{MODEL_SAVE_DIR}/model.safetensors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2629\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2630\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2631\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SoftLLaMAModel:\n\tMissing key(s) in state_dict: \"backbone.base_model.model.lm_head.weight\". \n\tUnexpected key(s) in state_dict: \"backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.nested_absmax\", \"backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.nested_quant_map\", \"backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.quant_map\", \"backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.absmax\", \"backbone.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4\", \"backbone.base_model.model.model.layers.0.se..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "OUTPUT_DIR = \"input/res\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "output_path = f\"{OUTPUT_DIR}/predictions.jsonl\"\n",
        "\n",
        "with open(output_path, \"w\") as f:\n",
        "    for idx, pred in enumerate(all_predictions):\n",
        "        record = {\"id\": str(idx), \"prediction\": pred}\n",
        "        f.write(json.dumps(record) + \"\\n\")\n",
        "\n",
        "print(f\"✅ Predictions saved to: {output_path}\")\n",
        "\n",
        "# Show distribution of predictions\n",
        "unique, counts = np.unique(all_predictions, return_counts=True)\n",
        "print(\"\\n📊 Prediction distribution:\")\n",
        "for score, count in zip(unique, counts):\n",
        "    print(f\"   Score {score}: {count} samples ({count/len(all_predictions)*100:.1f}%)\")\n",
        "\n",
        "# Download the file\n",
        "print(\"\\n📥 Downloading predictions file...\")\n",
        "from google.colab import files\n",
        "files.download(output_path)"
      ],
      "metadata": {
        "id": "tSSbt2Fhvdbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Upload solution file\n",
        "print(\"Upload solution.jsonl if you want to evaluate:\")\n",
        "uploaded_sol = files.upload()\n",
        "\n",
        "if \"solution.jsonl\" in uploaded_sol:\n",
        "    os.makedirs(\"input/ref\", exist_ok=True)\n",
        "    os.rename(\"solution.jsonl\", \"input/ref/solution.jsonl\")\n",
        "\n",
        "    # Run scoring (assuming you have scoring.py)\n",
        "    !python scoring.py input/ref/solution.jsonl input/res/predictions.jsonl output/scores.json\n",
        "\n",
        "    # Load and display results\n",
        "    if os.path.exists(\"output/scores.json\"):\n",
        "        with open(\"output/scores.json\") as f:\n",
        "            scores = json.load(f)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"🏆 FINAL RESULTS\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Spearman Correlation: {scores.get('spearman', 'N/A')}\")\n",
        "        print(f\"Accuracy: {scores.get('accuracy', 'N/A')}\")\n",
        "        print(\"=\"*70)\n",
        "else:\n",
        "    print(\"⚠️ No solution file uploaded. Skipping evaluation.\")"
      ],
      "metadata": {
        "id": "h3HjmK_Hvihp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 scoring.py input/ref/solution.jsonl input/res/predictions.jsonl output/scores.json\n",
        "!zip -j my_submission.zip input/res/predictions.jsonl\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"my_submission.zip\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "A_oSDWNyavBX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_SAVE_DIR = \"./best_llama_model\"\n",
        "trainer.save_model(MODEL_SAVE_DIR)\n",
        "tokenizer.save_pretrained(MODEL_SAVE_DIR)\n",
        "print(f\"✅ Model saved at {MODEL_SAVE_DIR}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "OE0WXpSSavBX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(len(dev_tok))):\n",
        "        sample = {k: dev_tok[i][k].unsqueeze(0).to(device) for k in [\"input_ids\",\"attention_mask\"]}\n",
        "        outputs = model(**sample)\n",
        "        logits = outputs[\"logits\"]\n",
        "        probs = torch.softmax(logits, dim=-1).cpu().numpy()[0]\n",
        "        centers = np.array([1,2,3,4,5])\n",
        "        pred_score = (probs * centers).sum()\n",
        "        pred_class = int(np.clip(np.round(pred_score), 1, 5))\n",
        "        all_predictions.append(pred_class)\n",
        "\n",
        "print(f\"✅ Predictions generated: {len(all_predictions)}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "iEGHA-IdavBX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "73752b4e-0f37-4732-f884-a88d14c36586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/588 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but got mat1 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_addmm)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-384507486.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_tok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdev_tok\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-633780861.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpooled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# mean pooling over sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# hidden = outputs.hidden_states.mean(dim=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# logits = self.classifier(hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mRuns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but got mat1 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_addmm)"
          ]
        }
      ],
      "execution_count": 38
    }
  ]
}